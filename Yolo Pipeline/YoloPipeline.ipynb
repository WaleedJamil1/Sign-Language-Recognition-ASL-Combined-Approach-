{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9e479cb06a7747708b3072c085d3f575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b382a52937e24a5db36b83036d4d42fa",
              "IPY_MODEL_3cac0a9825c9447b8b83b9657b5d961c",
              "IPY_MODEL_a1221b953d8247248018788f2024bbac"
            ],
            "layout": "IPY_MODEL_56f7bd6130a94817bb744ba319b7cf3d"
          }
        },
        "b382a52937e24a5db36b83036d4d42fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0177d42766b4f27a6713ad307fd2e57",
            "placeholder": "​",
            "style": "IPY_MODEL_b7afede7ab5845e8b9eba078afd23955",
            "value": "best.pt: 100%"
          }
        },
        "3cac0a9825c9447b8b83b9657b5d961c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683d01b87ced4859aed3b73054489fa8",
            "max": 14890201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6db701d5d6c43d581137045f5ada367",
            "value": 14890201
          }
        },
        "a1221b953d8247248018788f2024bbac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19cbdbd141cc4889a56db4d92a697aaa",
            "placeholder": "​",
            "style": "IPY_MODEL_02909ca4d6124c76ad6e68284f92354d",
            "value": " 14.9M/14.9M [00:01&lt;00:00, 14.8MB/s]"
          }
        },
        "56f7bd6130a94817bb744ba319b7cf3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0177d42766b4f27a6713ad307fd2e57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7afede7ab5845e8b9eba078afd23955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "683d01b87ced4859aed3b73054489fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6db701d5d6c43d581137045f5ada367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19cbdbd141cc4889a56db4d92a697aaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02909ca4d6124c76ad6e68284f92354d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4YI4GKDvLHD",
        "outputId": "67ee0884-c81a-46ba-d640-301135030d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 17533, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 17533 (delta 16), reused 0 (delta 0), pack-reused 17502 (from 5)\u001b[K\n",
            "Receiving objects: 100% (17533/17533), 16.61 MiB | 24.55 MiB/s, done.\n",
            "Resolving deltas: 100% (12005/12005), done.\n",
            "/content/yolov5\n",
            "Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (3.1.45)\n",
            "Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (2.0.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (11.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (1.16.1)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 14))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
            "Collecting ultralytics>=8.2.64 (from -r requirements.txt (line 18))\n",
            "  Downloading ultralytics-8.3.179-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 42)) (25.0)\n",
            "Requirement already satisfied: setuptools>=70.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (75.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.12)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->-r requirements.txt (line 12)) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->-r requirements.txt (line 15))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->-r requirements.txt (line 15)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics>=8.2.64->-r requirements.txt (line 18)) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics>=8.2.64->-r requirements.txt (line 18))\n",
            "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2025.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->-r requirements.txt (line 15)) (3.0.2)\n",
            "Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.179-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 thop-0.1.1.post2209072238 ultralytics-8.3.179 ultralytics-thop-2.0.15\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing huggingface_hub to download from HF repo\n",
        "!pip install huggingface_hub\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Downloading the best.pt from 'niki-stha/asl-detection-yolov5'\n",
        "model_path = hf_hub_download(repo_id=\"niki-stha/asl-detection-yolov5\", filename=\"best.pt\")\n",
        "\n",
        "print(\"Model downloaded to:\", model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "9e479cb06a7747708b3072c085d3f575",
            "b382a52937e24a5db36b83036d4d42fa",
            "3cac0a9825c9447b8b83b9657b5d961c",
            "a1221b953d8247248018788f2024bbac",
            "56f7bd6130a94817bb744ba319b7cf3d",
            "c0177d42766b4f27a6713ad307fd2e57",
            "b7afede7ab5845e8b9eba078afd23955",
            "683d01b87ced4859aed3b73054489fa8",
            "e6db701d5d6c43d581137045f5ada367",
            "19cbdbd141cc4889a56db4d92a697aaa",
            "02909ca4d6124c76ad6e68284f92354d"
          ]
        },
        "id": "XOdcIHbHwjFQ",
        "outputId": "680581f8-7c44-44c5-d8e4-953f7301447c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.34.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.8.3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "best.pt:   0%|          | 0.00/14.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e479cb06a7747708b3072c085d3f575"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded to: /root/.cache/huggingface/hub/models--niki-stha--asl-detection-yolov5/snapshots/9459dc7beba324f5b29414eaaf465161f9a4b69a/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "model_path = hf_hub_download(repo_id=\"niki-stha/asl-detection-yolov5\", filename=\"best.pt\")\n",
        "print(f\"Model downloaded to: {model_path}\")\n",
        "\n",
        "\n",
        "\n",
        "test_base_path = '/content/drive/MyDrive/Test_Alphabet'\n",
        "\n",
        "\n",
        "#  Loading the YOLOv5 model using the downloaded weights\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path, force_reload=True)\n",
        "\n",
        "#  Suppress AMP warnings and future warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"`torch.cuda.amp.autocast.*` is deprecated\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "model.conf = 0.60  # confidence threshold\n",
        "\n",
        "\n",
        "\n",
        "#  A-Z letters\n",
        "letters = [chr(c) for c in range(ord('A'), ord('Z') + 1)]\n",
        "\n",
        "#  Allowed image formats\n",
        "image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif'}\n",
        "\n",
        "#  Tracking\n",
        "total_images = 0\n",
        "total_detected = 0\n",
        "per_letter_stats = defaultdict(lambda: {'total': 0, 'detected': 0})\n",
        "\n",
        "# For evaluation\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "# 🚀 Inference loop\n",
        "for letter in letters:\n",
        "    folder_path = os.path.join(test_base_path, letter)\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Folder for letter {letter} not found, skipping.\")\n",
        "        continue\n",
        "\n",
        "    img_files = glob(os.path.join(folder_path, '*'))\n",
        "    total = 0\n",
        "    detected_count = 0\n",
        "\n",
        "    print(f\"\\nProcessing letter '{letter}' with {len(img_files)} files...\")\n",
        "\n",
        "    for img_path in img_files:\n",
        "        ext = os.path.splitext(img_path)[1].lower()\n",
        "        if ext not in image_extensions:\n",
        "            print(f\"Skipping non-image file: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        total += 1\n",
        "        total_images += 1\n",
        "\n",
        "        results = model(img_path)\n",
        "\n",
        "        if len(results.xyxy[0]) > 0:\n",
        "            # Pick the most confident detection\n",
        "            pred_class = int(results.pred[0][0][-1].item())\n",
        "            class_name = model.names[pred_class]\n",
        "            y_pred.append(class_name)\n",
        "            total_detected += 1\n",
        "            detected_count += 1\n",
        "        else:\n",
        "            y_pred.append('None')  # if nothing detected\n",
        "\n",
        "        y_true.append(letter)\n",
        "\n",
        "    per_letter_stats[letter]['total'] = total\n",
        "    per_letter_stats[letter]['detected'] = detected_count\n",
        "\n",
        "    accuracy = detected_count / total * 100 if total > 0 else 0\n",
        "    print(f\"Letter '{letter}': {detected_count}/{total} detected ({accuracy:.2f}%)\")\n",
        "\n",
        "#  Overall Accuracy\n",
        "overall_accuracy = total_detected / total_images * 100 if total_images > 0 else 0\n",
        "\n",
        "print(\"\\n=== Evaluation Summary ===\")\n",
        "print(f\"Total images evaluated: {total_images}\")\n",
        "print(f\"Total detections: {total_detected}\")\n",
        "print(f\"✅ Overall Detection Accuracy: {overall_accuracy:.2f}%\")\n",
        "\n",
        "#  Classification Report\n",
        "report = classification_report(y_true, y_pred, labels=letters, output_dict=True, zero_division=0)\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "report_csv_path = \"/content/yolo_letter_classification_report.csv\"\n",
        "report_df.to_csv(report_csv_path)\n",
        "print(f\"\\n📄 Classification report saved to: {report_csv_path}\")\n",
        "\n",
        "#  Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred, labels=letters)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=letters, columns=letters)\n",
        "conf_matrix_path = \"/content/yolo_letter_confusion_matrix.csv\"\n",
        "conf_matrix_df.to_csv(conf_matrix_path)\n",
        "print(f\"📄 Confusion matrix saved to: {conf_matrix_path}\")\n",
        "\n",
        "#  Display Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(18, 14))\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt=\"d\", cmap=\"YlGnBu\", linewidths=0.5)\n",
        "plt.title(\"YOLOv5 Letter Classification - Confusion Matrix\", fontsize=16)\n",
        "plt.ylabel(\"True Label\", fontsize=14)\n",
        "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"/content/yolo_letter_confusion_matrix_heatmap.png\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5Hmq2DYw3vd",
        "outputId": "00bacb93-7584-494c-d26e-39cbf51d8059"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded to: /root/.cache/huggingface/hub/models--niki-stha--asl-detection-yolov5/snapshots/9459dc7beba324f5b29414eaaf465161f9a4b69a/best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/hub.py:330: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 2025-8-18 Python-3.11.13 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7313943 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing letter 'A' with 100 files...\n",
            "Letter 'A': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'B' with 100 files...\n",
            "Letter 'B': 87/100 detected (87.00%)\n",
            "\n",
            "Processing letter 'C' with 100 files...\n",
            "Letter 'C': 95/100 detected (95.00%)\n",
            "\n",
            "Processing letter 'D' with 100 files...\n",
            "Letter 'D': 75/100 detected (75.00%)\n",
            "\n",
            "Processing letter 'E' with 100 files...\n",
            "Letter 'E': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'F' with 100 files...\n",
            "Letter 'F': 95/100 detected (95.00%)\n",
            "\n",
            "Processing letter 'G' with 100 files...\n",
            "Letter 'G': 72/100 detected (72.00%)\n",
            "\n",
            "Processing letter 'H' with 100 files...\n",
            "Letter 'H': 79/100 detected (79.00%)\n",
            "\n",
            "Processing letter 'I' with 100 files...\n",
            "Letter 'I': 84/100 detected (84.00%)\n",
            "\n",
            "Processing letter 'J' with 100 files...\n",
            "Letter 'J': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'K' with 100 files...\n",
            "Letter 'K': 78/100 detected (78.00%)\n",
            "\n",
            "Processing letter 'L' with 100 files...\n",
            "Letter 'L': 95/100 detected (95.00%)\n",
            "\n",
            "Processing letter 'M' with 100 files...\n",
            "Letter 'M': 86/100 detected (86.00%)\n",
            "\n",
            "Processing letter 'N' with 100 files...\n",
            "Letter 'N': 89/100 detected (89.00%)\n",
            "\n",
            "Processing letter 'O' with 100 files...\n",
            "Letter 'O': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'P' with 100 files...\n",
            "Letter 'P': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'Q' with 100 files...\n",
            "Letter 'Q': 94/100 detected (94.00%)\n",
            "\n",
            "Processing letter 'R' with 100 files...\n",
            "Letter 'R': 66/100 detected (66.00%)\n",
            "\n",
            "Processing letter 'S' with 100 files...\n",
            "Letter 'S': 94/100 detected (94.00%)\n",
            "\n",
            "Processing letter 'T' with 100 files...\n",
            "Letter 'T': 81/100 detected (81.00%)\n",
            "\n",
            "Processing letter 'U' with 100 files...\n",
            "Letter 'U': 28/100 detected (28.00%)\n",
            "\n",
            "Processing letter 'V' with 100 files...\n",
            "Letter 'V': 60/100 detected (60.00%)\n",
            "\n",
            "Processing letter 'W' with 100 files...\n",
            "Letter 'W': 61/100 detected (61.00%)\n",
            "\n",
            "Processing letter 'X' with 100 files...\n",
            "Letter 'X': 69/100 detected (69.00%)\n",
            "\n",
            "Processing letter 'Y' with 100 files...\n",
            "Letter 'Y': 91/100 detected (91.00%)\n",
            "\n",
            "Processing letter 'Z' with 100 files...\n",
            "Letter 'Z': 69/100 detected (69.00%)\n",
            "\n",
            "=== Evaluation Summary ===\n",
            "Total images evaluated: 2600\n",
            "Total detections: 2143\n",
            "✅ Overall Detection Accuracy: 82.42%\n",
            "\n",
            "📄 Classification report saved to: /content/yolo_letter_classification_report.csv\n",
            "📄 Confusion matrix saved to: /content/yolo_letter_confusion_matrix.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import warnings\n",
        "from glob import glob\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        ")\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Setting Path to Testing Dataset\n",
        "test_base_path = \"/content/drive/MyDrive/Test_Alphabet\"\n",
        "\n",
        "# Confidence threshold for YOLO detections\n",
        "CONF_THRESH = 0.60\n",
        "\n",
        "# Evaluation Output paths\n",
        "report_csv_path = \"/content/yolo_letter_classification_report.csv\"\n",
        "conf_matrix_path = \"/content/yolo_letter_confusion_matrix.csv\"\n",
        "conf_matrix_png_path = \"/content/yolo_letter_confusion_matrix_heatmap.png\"\n",
        "metrics_summary_path = \"/content/yolo_letter_metrics_summary.csv\"\n",
        "\n",
        "\n",
        "#  Download weights from HF Hub\n",
        "\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"niki-stha/asl-detection-yolov5\",\n",
        "    filename=\"best.pt\"\n",
        ")\n",
        "print(f\"Model downloaded to: {model_path}\")\n",
        "\n",
        "\n",
        "# Loading the model\n",
        "\n",
        "# Suppress specific warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"`torch.cuda.amp.autocast.*` is deprecated\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Load YOLOv5 custom model\n",
        "model = torch.hub.load(\"ultralytics/yolov5\", \"custom\", path=model_path, force_reload=True)\n",
        "model.conf = CONF_THRESH  # confidence threshold\n",
        "\n",
        "\n",
        "#  Labels & bookkeeping\n",
        "\n",
        "letters = [chr(c) for c in range(ord(\"A\"), ord(\"Z\") + 1)]\n",
        "image_extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}\n",
        "\n",
        "total_images = 0\n",
        "total_detected = 0\n",
        "per_letter_stats = defaultdict(lambda: {\"total\": 0, \"detected\": 0})\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "\n",
        "#  Inference loop\n",
        "\n",
        "for letter in letters:\n",
        "    folder_path = os.path.join(test_base_path, letter)\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Folder for letter {letter} not found, skipping.\")\n",
        "        continue\n",
        "\n",
        "    img_files = glob(os.path.join(folder_path, \"*\"))\n",
        "    total = 0\n",
        "    detected_count = 0\n",
        "\n",
        "    print(f\"\\nProcessing letter '{letter}' with {len(img_files)} files...\")\n",
        "\n",
        "    for img_path in img_files:\n",
        "        ext = os.path.splitext(img_path)[1].lower()\n",
        "        if ext not in image_extensions:\n",
        "            # Skip non-image files\n",
        "            continue\n",
        "\n",
        "        total += 1\n",
        "        total_images += 1\n",
        "\n",
        "        # Run inference\n",
        "        results = model(img_path)\n",
        "\n",
        "        # YOLOv5 returns detections as [x1, y1, x2, y2, conf, cls] in results.xyxy[0]\n",
        "        det = results.xyxy[0]\n",
        "        if det is not None and len(det) > 0:\n",
        "            # pick the most confident detection\n",
        "\n",
        "            top_idx = det[:, 4].argmax().item()\n",
        "            pred_class_idx = int(det[top_idx, 5].item())\n",
        "            class_name = str(model.names[pred_class_idx])\n",
        "\n",
        "            y_pred.append(class_name)\n",
        "            total_detected += 1\n",
        "            detected_count += 1\n",
        "        else:\n",
        "            # nothing detected for this image\n",
        "            y_pred.append(\"None\")\n",
        "\n",
        "        y_true.append(letter)\n",
        "\n",
        "    per_letter_stats[letter][\"total\"] = total\n",
        "    per_letter_stats[letter][\"detected\"] = detected_count\n",
        "\n",
        "    accuracy_letter = (detected_count / total * 100) if total > 0 else 0.0\n",
        "    print(f\"Letter '{letter}': {detected_count}/{total} detected ({accuracy_letter:.2f}%)\")\n",
        "\n",
        "\n",
        "#  Overall detection accuracy\n",
        "\n",
        "overall_detection_accuracy = (total_detected / total_images * 100) if total_images > 0 else 0.0\n",
        "\n",
        "print(\"\\n=== Evaluation Summary ===\")\n",
        "print(f\"Total images evaluated: {total_images}\")\n",
        "print(f\"Total detections: {total_detected}\")\n",
        "print(f\"✅ Overall Detection Accuracy: {overall_detection_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "#  Classification metrics (A–Z only)\n",
        "\n",
        "# Classification Accuracy\n",
        "clf_accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "# Macro-averaged Precision/Recall/F1 across A–Z (treat each class equally)\n",
        "macro_p, macro_r, macro_f1, _ = precision_recall_fscore_support(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    labels=letters,        # restrict to A–Z\n",
        "    average=\"macro\",\n",
        "    zero_division=0\n",
        ")\n",
        "\n",
        "print(\"\\n=== Classification Metrics (A–Z) ===\")\n",
        "print(f\"🎯 Classification Accuracy: {clf_accuracy*100:.2f}%\")\n",
        "print(f\"📌 Macro Precision: {macro_p:.4f}\")\n",
        "print(f\"📌 Macro Recall:    {macro_r:.4f}\")\n",
        "print(f\"📌 Macro F1-Score:  {macro_f1:.4f}\")\n",
        "\n",
        "# Save compact metrics summary\n",
        "pd.DataFrame(\n",
        "    {\n",
        "        \"metric\": [\"classification_accuracy\", \"macro_precision\", \"macro_recall\", \"macro_f1\", \"overall_detection_accuracy\"],\n",
        "        \"value\":  [clf_accuracy,              macro_p,           macro_r,       macro_f1,   overall_detection_accuracy/100.0],\n",
        "    }\n",
        ").to_csv(metrics_summary_path, index=False)\n",
        "print(f\"📄 Metrics summary saved to: {metrics_summary_path}\")\n",
        "\n",
        "\n",
        "#  Classification report (per-class) — A–Z\n",
        "\n",
        "report = classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    labels=letters,\n",
        "    output_dict=True,\n",
        "    zero_division=0\n",
        ")\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "report_df.to_csv(report_csv_path)\n",
        "print(f\"📄 Classification report saved to: {report_csv_path}\")\n",
        "\n",
        "\n",
        "#  Confusion Matrix (A–Z)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred, labels=letters)\n",
        "conf_matrix_df = pd.DataFrame(conf_matrix, index=letters, columns=letters)\n",
        "conf_matrix_df.to_csv(conf_matrix_path)\n",
        "print(f\"📄 Confusion matrix saved to: {conf_matrix_path}\")\n",
        "\n",
        "\n",
        "#  Confusion Matrix Heatmap\n",
        "\n",
        "plt.figure(figsize=(18, 14))\n",
        "sns.heatmap(conf_matrix_df, annot=True, fmt=\"d\", cmap=\"YlGnBu\", linewidths=0.5)\n",
        "plt.title(\"YOLOv5 Letter Classification - Confusion Matrix\", fontsize=16)\n",
        "plt.ylabel(\"True Label\", fontsize=14)\n",
        "plt.xlabel(\"Predicted Label\", fontsize=14)\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.yticks(rotation=0)\n",
        "plt.tight_layout()\n",
        "plt.savefig(conf_matrix_png_path, dpi=150)\n",
        "print(f\"🖼️ Confusion matrix heatmap saved to: {conf_matrix_png_path}\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIpWJCnh3L86",
        "outputId": "593c9cb8-1ffc-40c0-b7c1-cd40afb0baf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model downloaded to: /root/.cache/huggingface/hub/models--niki-stha--asl-detection-yolov5/snapshots/9459dc7beba324f5b29414eaaf465161f9a4b69a/best.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2025-8-16 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7313943 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing letter 'A' with 100 files...\n",
            "Letter 'A': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'B' with 100 files...\n",
            "Letter 'B': 87/100 detected (87.00%)\n",
            "\n",
            "Processing letter 'C' with 100 files...\n",
            "Letter 'C': 95/100 detected (95.00%)\n",
            "\n",
            "Processing letter 'D' with 100 files...\n",
            "Letter 'D': 75/100 detected (75.00%)\n",
            "\n",
            "Processing letter 'E' with 100 files...\n",
            "Letter 'E': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'F' with 100 files...\n",
            "Letter 'F': 95/100 detected (95.00%)\n",
            "\n",
            "Processing letter 'G' with 100 files...\n",
            "Letter 'G': 72/100 detected (72.00%)\n",
            "\n",
            "Processing letter 'H' with 100 files...\n",
            "Letter 'H': 79/100 detected (79.00%)\n",
            "\n",
            "Processing letter 'I' with 100 files...\n",
            "Letter 'I': 84/100 detected (84.00%)\n",
            "\n",
            "Processing letter 'J' with 100 files...\n",
            "Letter 'J': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'K' with 100 files...\n",
            "Letter 'K': 78/100 detected (78.00%)\n",
            "\n",
            "Processing letter 'L' with 100 files...\n",
            "Letter 'L': 95/100 detected (95.00%)\n",
            "\n",
            "Processing letter 'M' with 100 files...\n",
            "Letter 'M': 86/100 detected (86.00%)\n",
            "\n",
            "Processing letter 'N' with 100 files...\n",
            "Letter 'N': 89/100 detected (89.00%)\n",
            "\n",
            "Processing letter 'O' with 100 files...\n",
            "Letter 'O': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'P' with 100 files...\n",
            "Letter 'P': 99/100 detected (99.00%)\n",
            "\n",
            "Processing letter 'Q' with 100 files...\n",
            "Letter 'Q': 94/100 detected (94.00%)\n",
            "\n",
            "Processing letter 'R' with 100 files...\n",
            "Letter 'R': 66/100 detected (66.00%)\n",
            "\n",
            "Processing letter 'S' with 100 files...\n",
            "Letter 'S': 94/100 detected (94.00%)\n",
            "\n",
            "Processing letter 'T' with 100 files...\n",
            "Letter 'T': 81/100 detected (81.00%)\n",
            "\n",
            "Processing letter 'U' with 100 files...\n",
            "Letter 'U': 28/100 detected (28.00%)\n",
            "\n",
            "Processing letter 'V' with 100 files...\n",
            "Letter 'V': 60/100 detected (60.00%)\n",
            "\n",
            "Processing letter 'W' with 100 files...\n",
            "Letter 'W': 62/100 detected (62.00%)\n",
            "\n",
            "Processing letter 'X' with 100 files...\n",
            "Letter 'X': 69/100 detected (69.00%)\n",
            "\n",
            "Processing letter 'Y' with 100 files...\n",
            "Letter 'Y': 91/100 detected (91.00%)\n",
            "\n",
            "Processing letter 'Z' with 100 files...\n",
            "Letter 'Z': 69/100 detected (69.00%)\n",
            "\n",
            "=== Evaluation Summary ===\n",
            "Total images evaluated: 2600\n",
            "Total detections: 2144\n",
            "✅ Overall Detection Accuracy: 82.46%\n",
            "\n",
            "=== Classification Metrics (A–Z) ===\n",
            "🎯 Classification Accuracy: 82.27%\n",
            "📌 Macro Precision: 0.9977\n",
            "📌 Macro Recall:    0.8227\n",
            "📌 Macro F1-Score:  0.8913\n",
            "📄 Metrics summary saved to: /content/yolo_letter_metrics_summary.csv\n",
            "📄 Classification report saved to: /content/yolo_letter_classification_report.csv\n",
            "📄 Confusion matrix saved to: /content/yolo_letter_confusion_matrix.csv\n",
            "🖼️ Confusion matrix heatmap saved to: /content/yolo_letter_confusion_matrix_heatmap.png\n"
          ]
        }
      ]
    }
  ]
}