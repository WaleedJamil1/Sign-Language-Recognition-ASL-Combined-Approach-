{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip install mediapipe\n",
        "!pip install scikit-learn\n",
        "!pip install joblib\n",
        "!pip install pandas"
      ],
      "metadata": {
        "id": "djqOxyflosNZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f250b14-337f-48f0-f611-c7a79253f087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.179)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.15)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Collecting numpy>=1.23.0 (from ultralytics)\n",
            "  Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "e1877be25eac4b42ba43e104d8fadb8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning and installing YOLOv5\n",
        "!git clone https://github.com/ultralytics/yolov5.git\n",
        "%cd yolov5\n",
        "%pip install -r requirements.txt --quiet"
      ],
      "metadata": {
        "id": "39H6YKPmoNiy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c4d9d6-fb16-4389-eed5-49a27a5fe8ad"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n",
            "/content/yolov5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import joblib\n",
        "import torch\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "xMheowsKovWW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import mediapipe as mp\n",
        "from pathlib import Path\n",
        "from models.common import DetectMultiBackend\n",
        "from utils.general import non_max_suppression\n",
        "from utils.torch_utils import select_device\n",
        "\n",
        "# Load YOLOv5 model\n",
        "yolo_model_path = '/content/best.pt'  # your pretrained model path\n",
        "device = select_device('')\n",
        "yolo_model = DetectMultiBackend(yolo_model_path, device=device)\n",
        "yolo_model.warmup(imgsz=(1, 3, 640, 640))\n",
        "\n",
        "# Load MediaPipe\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n",
        "\n",
        "# Extract YOLO features: return 1-hot for detected class\n",
        "def extract_yolo_feature(img, num_classes=26):\n",
        "    try:\n",
        "        img_resized = cv2.resize(img, (640, 640))\n",
        "        img_rgb = img_resized[..., ::-1].transpose((2, 0, 1))\n",
        "        img_rgb = np.ascontiguousarray(img_rgb)\n",
        "        img_tensor = torch.from_numpy(img_rgb).to(device).float() / 255.0\n",
        "        img_tensor = img_tensor.unsqueeze(0)\n",
        "\n",
        "        pred = yolo_model(img_tensor, augment=False, visualize=False)\n",
        "        pred = non_max_suppression(pred, conf_thres=0.5)[0]\n",
        "\n",
        "        vec = np.zeros(num_classes)\n",
        "        if pred is not None and len(pred):\n",
        "            cls_id = int(pred[0][5].item())\n",
        "            vec[cls_id] = 1\n",
        "        return vec\n",
        "    except:\n",
        "        return np.zeros(num_classes)\n",
        "\n",
        "# Extract MediaPipe features\n",
        "def extract_mediapipe_feature(img):\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    results = hands.process(img_rgb)\n",
        "    if results.multi_hand_landmarks:\n",
        "        landmarks = []\n",
        "        for lm in results.multi_hand_landmarks[0].landmark:\n",
        "            landmarks.extend([lm.x, lm.y, lm.z])\n",
        "        return np.array(landmarks)\n",
        "    return np.zeros(63)  # 21 landmarks * 3\n",
        "\n"
      ],
      "metadata": {
        "id": "QkigSYeEo3zU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186cd06d-4a6b-4561-c20e-3ac7fbcc3bf3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-425-g85acef3a Python-3.11.13 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7313943 parameters, 0 gradients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Define the dataset directory and label set (A-Z)\n",
        "dataset_path = '/content/drive/MyDrive/Train_Alphabet'\n",
        "labels = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
        "\n",
        "# Feature and label storage\n",
        "X, y = [], []\n",
        "\n",
        "# Iterate through label folders\n",
        "for label_idx, label in enumerate(labels):\n",
        "    folder = os.path.join(dataset_path, label)\n",
        "    if not os.path.isdir(folder):\n",
        "        print(f\"❌ Skipping missing folder: {label}\")\n",
        "        continue\n",
        "\n",
        "    image_files = os.listdir(folder)\n",
        "    print(f\"🔍 Processing {label} ({len(image_files)} images)\")\n",
        "\n",
        "    for fname in image_files:\n",
        "        path = os.path.join(folder, fname)\n",
        "        img = cv2.imread(path)\n",
        "\n",
        "        if img is None:\n",
        "            print(f\"⚠️ Skipping unreadable image: {path}\")\n",
        "            continue\n",
        "\n",
        "        # Extract fused features from YOLO + MediaPipe\n",
        "        try:\n",
        "            yolo_feat = extract_yolo_feature(img)\n",
        "            mp_feat = extract_mediapipe_feature(img)\n",
        "            fused_feat = np.concatenate([yolo_feat, mp_feat])\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Feature extraction failed for {fname}: {e}\")\n",
        "            continue\n",
        "\n",
        "        X.append(fused_feat)\n",
        "        y.append(label_idx)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"\\n✅ Feature extraction complete.\")\n",
        "print(f\"📊 Total samples: {len(X)}, Feature dimension: {X.shape[1]}\")\n"
      ],
      "metadata": {
        "id": "ncvqfBt0pdFS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "6e6f19db-fc2d-4abf-f700-9b18de313fb5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Processing A (920 images)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3894642825.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Save the trained model\n",
        "import joblib\n",
        "joblib.dump(clf, '/content/early_fusion_model.pkl')\n",
        "print(\"✅ Model trained and saved to '/content/early_fusion_model.pkl'\")"
      ],
      "metadata": {
        "id": "QuLBnMwipl04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import joblib\n",
        "import mediapipe as mp\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "from utils.general import non_max_suppression\n",
        "from utils.torch_utils import select_device\n",
        "from models.common import DetectMultiBackend\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  Loading trained early-fusion classifier\n",
        "clf = joblib.load('/content/early_fusion_model.pkl')  # path to trained model\n",
        "\n",
        "# Set up YOLOv5\n",
        "yolo_model_path = '/content/best.pt'\n",
        "device = select_device('')\n",
        "yolo_model = DetectMultiBackend(yolo_model_path, device=device)\n",
        "yolo_model.warmup(imgsz=(1, 3, 640, 640))\n",
        "\n",
        "# Set up MediaPipe\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\n",
        "\n",
        "# Feature Extraction Functions\n",
        "def extract_yolo_feature(img, num_classes=26, conf_threshold=0.6):\n",
        "    try:\n",
        "        img_resized = cv2.resize(img, (640, 640))\n",
        "        img_rgb = img_resized[..., ::-1].transpose((2, 0, 1))  # BGR->RGB, HWC->CHW\n",
        "        img_rgb = np.ascontiguousarray(img_rgb)\n",
        "        img_tensor = torch.from_numpy(img_rgb).to(device).float() / 255.0\n",
        "        if img_tensor.ndimension() == 3:\n",
        "            img_tensor = img_tensor.unsqueeze(0)\n",
        "\n",
        "        pred = yolo_model(img_tensor)\n",
        "        pred = non_max_suppression(pred, conf_thres=conf_threshold)[0]\n",
        "\n",
        "        vec = np.zeros(num_classes, dtype=np.float32)\n",
        "        if pred is not None and len(pred):\n",
        "            class_id = int(pred[0][5].item())\n",
        "            if 0 <= class_id < num_classes:\n",
        "                vec[class_id] = 1.0\n",
        "        return vec\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def extract_mediapipe_feature(img):\n",
        "    try:\n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        results = hands.process(img_rgb)\n",
        "        if results.multi_hand_landmarks:\n",
        "            features = []\n",
        "            for lm in results.multi_hand_landmarks[0].landmark:\n",
        "                features.extend([lm.x, lm.y, lm.z])\n",
        "            return np.array(features, dtype=np.float32)  # 63 elements\n",
        "        else:\n",
        "            return None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "#  Inference on test dataset\n",
        "test_path = '/content/drive/MyDrive/Test_Alphabet'\n",
        "labels = [chr(i) for i in range(ord('A'), ord('Z')+1)]\n",
        "confidence_threshold = 0.6\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "\n",
        "for label_idx, label in enumerate(labels):\n",
        "    folder = os.path.join(test_path, label)\n",
        "    if not os.path.isdir(folder):\n",
        "        continue\n",
        "\n",
        "    for fname in os.listdir(folder):\n",
        "        path = os.path.join(folder, fname)\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            yolo_feat = extract_yolo_feature(img, conf_threshold=confidence_threshold)\n",
        "            mp_feat = extract_mediapipe_feature(img)\n",
        "\n",
        "            if yolo_feat is None or mp_feat is None:\n",
        "                pred = -1  # mark failure\n",
        "            else:\n",
        "                fused_feat = np.concatenate([yolo_feat, mp_feat])  # 26 + 63 = 89 features\n",
        "                pred = clf.predict([fused_feat])[0]\n",
        "        except Exception as e:\n",
        "            print(f\" Feature extraction failed for {fname}: {e}\")\n",
        "            pred = -1\n",
        "\n",
        "        y_true.append(label_idx)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "# Original Report\n",
        "total = len(y_true)\n",
        "correct = sum(yt == yp for yt, yp in zip(y_true, y_pred))\n",
        "accuracy = correct / total * 100 if total > 0 else 0.0\n",
        "\n",
        "valid_idx = [i for i, p in enumerate(y_pred) if p != -1]\n",
        "y_true_valid = [y_true[i] for i in valid_idx]\n",
        "y_pred_valid = [y_pred[i] for i in valid_idx]\n",
        "\n",
        "if len(valid_idx) > 0:\n",
        "    print(\"\\n Classification Report (valid predictions only):\")\n",
        "    print(classification_report(y_true_valid, y_pred_valid, target_names=labels, zero_division=0))\n",
        "else:\n",
        "    print(\" No valid predictions.\")\n",
        "\n",
        "print(f\"\\n Total Samples: {total}\")\n",
        "print(f\" Failed samples (treated as incorrect): {total - len(valid_idx)}\")\n",
        "print(f\" Overall Accuracy (including failures): {accuracy:.2f}%\")\n",
        "\n",
        "#  Evaluation: Accuracy, Macro P/R/F1, Confusion Matrix (A–Z)\n",
        "acc_overall = accuracy_score(y_true, y_pred) if total > 0 else 0.0\n",
        "print(\"\\n=== Overall Accuracy (A–Z; failures counted as incorrect) ===\")\n",
        "print(f\"Accuracy: {acc_overall * 100:.2f}%\")\n",
        "\n",
        "prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    labels=list(range(len(labels))),   # only A–Z classes\n",
        "    average='macro',\n",
        "    zero_division=0\n",
        ")\n",
        "print(\"\\n=== Macro-Averaged Metrics (A–Z only) ===\")\n",
        "print(f\"Precision (Macro): {prec_macro:.4f}\")\n",
        "print(f\"Recall (Macro):    {rec_macro:.4f}\")\n",
        "print(f\"F1-Score (Macro):  {f1_macro:.4f}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n",
        "plt.figure(figsize=(16, 12))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix — ASL Letters (Early Fusion)')\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/confusion_matrix_early_fusion_letters.png', dpi=200, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\" Saved confusion matrix to: /content/confusion_matrix_early_fusion_letters.png\")\n"
      ],
      "metadata": {
        "id": "PNbtO2TTpo5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365f339e-9031-4e5f-a085-f8c2ff935de4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 🚀 v7.0-425-g85acef3a Python-3.11.13 torch-2.6.0+cu124 CPU\n",
            "\n",
            "Fusing layers... \n",
            "custom_YOLOv5s summary: 182 layers, 7313943 parameters, 0 gradients\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Classification Report (valid predictions only):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       1.00      0.99      0.99        92\n",
            "           B       1.00      1.00      1.00        89\n",
            "           C       1.00      1.00      1.00        92\n",
            "           D       0.99      1.00      0.99        82\n",
            "           E       1.00      1.00      1.00        76\n",
            "           F       0.99      1.00      0.99        90\n",
            "           G       1.00      1.00      1.00        98\n",
            "           H       1.00      0.99      0.99        97\n",
            "           I       1.00      1.00      1.00        91\n",
            "           J       1.00      1.00      1.00        91\n",
            "           K       0.99      0.99      0.99        92\n",
            "           L       1.00      1.00      1.00        93\n",
            "           M       1.00      1.00      1.00        85\n",
            "           N       1.00      1.00      1.00        93\n",
            "           O       0.99      1.00      0.99        96\n",
            "           P       0.99      1.00      0.99        91\n",
            "           Q       1.00      0.99      0.99        88\n",
            "           R       1.00      1.00      1.00        88\n",
            "           S       1.00      1.00      1.00        91\n",
            "           T       1.00      1.00      1.00        95\n",
            "           U       0.99      0.98      0.98        89\n",
            "           V       0.99      1.00      0.99        83\n",
            "           W       1.00      1.00      1.00        94\n",
            "           X       1.00      0.99      0.99        83\n",
            "           Y       1.00      1.00      1.00        82\n",
            "           Z       1.00      1.00      1.00        86\n",
            "\n",
            "    accuracy                           1.00      2327\n",
            "   macro avg       1.00      1.00      1.00      2327\n",
            "weighted avg       1.00      1.00      1.00      2327\n",
            "\n",
            "\n",
            " Total Samples: 2600\n",
            " Failed samples (treated as incorrect): 273\n",
            " Overall Accuracy (including failures): 89.23%\n",
            "\n",
            "=== Overall Accuracy (A–Z; failures counted as incorrect) ===\n",
            "Accuracy: 89.23%\n",
            "\n",
            "=== Macro-Averaged Metrics (A–Z only) ===\n",
            "Precision (Macro): 0.9970\n",
            "Recall (Macro):    0.8923\n",
            "F1-Score (Macro):  0.9410\n",
            " Saved confusion matrix to: /content/confusion_matrix_early_fusion_letters.png\n"
          ]
        }
      ]
    }
  ]
}